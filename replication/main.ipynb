{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Drawing empirical means and covariances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import Tuple as T, Optional as O\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.covariance import LedoitWolf\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from scipy.optimize import minimize, Bounds\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_samples\n",
    "\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Denoising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitKDE(obs, bandwidth=.25, kernel='gaussian', x=None):\n",
    "    \"\"\"\n",
    "    по сути генерируем функцию плотности на основе наблюдений `obs`\n",
    "    а затем возвращаем вероятности каждой из точек\n",
    "    \"\"\"\n",
    "\n",
    "    # Fit kernel to a series of obs, and derive the prob of obs\n",
    "    # x is the array of values on which the fit KDE will be evaluated\n",
    "\n",
    "    # observations to column vector\n",
    "    obs = obs.reshape(-1, 1) if len(obs.shape) == 1 else obs\n",
    "    kde = KernelDensity(kernel=kernel, bandwidth=bandwidth).fit(obs)\n",
    "\n",
    "    # if x were not passed, then we use unique observations\n",
    "    x = np.unique(obs).reshape(-1, 1) if x is None else x\n",
    "    x = x.reshape(-1, 1) if len(x.shape) == 1 else x\n",
    "\n",
    "    logprob = kde.score_samples(x)  # log(density)\n",
    "    pdf = pd.Series(np.exp(logprob), index=x.flatten())\n",
    "    return pdf\n",
    "\n",
    "\n",
    "def mpPDF(var, q, pts):\n",
    "    \"\"\"Marcenko-Pastur pdf\"\"\"\n",
    "    # q=T/N\n",
    "    var = var[0]\n",
    "    eigen_min = var * (1 - (1 / q)**.5)**2\n",
    "    eigen_max = var * (1 + (1 / q)**.5)**2\n",
    "\n",
    "    eigen_values = np.linspace(eigen_min, eigen_max, pts)\n",
    "    pdf = q / (2 * np.pi * var * eigen_values) * \\\n",
    "        ((eigen_max - eigen_values) * (eigen_values-eigen_min))**.5\n",
    "        \n",
    "    pdf = pd.Series(pdf, index=eigen_values.flatten())\n",
    "    return pdf\n",
    "\n",
    "\n",
    "def errPDFs(var, eigen_values, q, bandwidth, pts=1000):\n",
    "    # Fit error\n",
    "    pdf0 = mpPDF(var, q, pts)  # theoretical pdf\n",
    "    pdf1 = fitKDE(eigen_values, bandwidth,\n",
    "                  x=pdf0.index.values)  # empirical pdf\n",
    "    sse = np.sum((pdf1 - pdf0)**2)\n",
    "    return sse\n",
    "\n",
    "\n",
    "def find_max_eigen_values(eigen_values, q, bandwidth):\n",
    "    \"\"\" Точка входа \n",
    "\n",
    "    This function uses a Kernel Density Estimate (KDE) algorithm to fit the\n",
    "    Marcenko-Pastur distribution to the empirical distribution of eigenvalues.\n",
    "    This has the effect of separating noise-related eigenvalues from \n",
    "    signal-related eigenvalues.\n",
    "    \"\"\"\n",
    "    # Find max random eVal by fitting Marcenko's dist to the empirical one\n",
    "    # this is done to define variance in order to use formula for maximum \n",
    "    # eigen value\n",
    "    \n",
    "    out = minimize(\n",
    "        lambda *x: errPDFs(*x),\n",
    "        np.array([0.5]),\n",
    "        args=(eigen_values, q, bandwidth),\n",
    "        bounds=Bounds(1E-5, 1-1E-5)\n",
    "    )\n",
    "    \n",
    "    var = out['x'][0] if out['success'] else 1\n",
    "    eMax = var * (1 + (1/q)**.5)**2\n",
    "    \n",
    "    # print('OPTIMIZED: ', var, eMax)\n",
    "    return eMax\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Estimating $\\hat\\omega^*$ from $\\{\\hat\\mu, \\hat V\\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation of NCO algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def clusterKMeansBase(corr0: np.ndarray, maxNumClusters=None, n_init: int = 10):\n",
    "    dist, silh = ((1 - corr0.fillna(0)) /\n",
    "                  2.)**.5, pd.Series()  # distance matrix\n",
    "\n",
    "    if maxNumClusters is None:\n",
    "        maxNumClusters = corr0.shape[0] / 2\n",
    "\n",
    "    for init in range(n_init):\n",
    "        for i in range(2, maxNumClusters + 1):  # find optimal num clusters\n",
    "            kmeans_ = KMeans(n_clusters=i, n_jobs=1, n_init=1)\n",
    "            kmeans_ = kmeans_.fit(dist)\n",
    "            silh_ = silhouette_samples(dist, kmeans_.labels_)\n",
    "            stat = (silh_.mean()/silh_.std(), silh.mean()/silh.std())\n",
    "            if np.isnan(stat[1]) or stat[0] > stat[1]:\n",
    "                silh, kmeans = silh_, kmeans_\n",
    "\n",
    "    newIdx = np.argsort(kmeans.labels_)\n",
    "    corr1 = corr0.iloc[newIdx]  # reorder rows\n",
    "    corr1 = corr1.iloc[:, newIdx]  # reorder columns\n",
    "    clstrs = {\n",
    "        i: corr0.columns[np.where(kmeans.labels_ == i)[0]].tolist() for\n",
    "        i in np.unique(kmeans.labels_)}  # cluster members\n",
    "    silh = pd.Series(silh, index=dist.index)\n",
    "    return corr1, clstrs, silh\n",
    "\n",
    "\n",
    "def optPort(cov, mu=None):\n",
    "    inv = np.linalg.inv(cov)\n",
    "    ones = np.ones(shape=(inv.shape[0], 1))\n",
    "    mu = ones if mu is None else mu\n",
    "    w = np.dot(inv, mu)\n",
    "    w /= np.dot(ones.T, w)\n",
    "    return w\n",
    "\n",
    "\n",
    "def optPort_nco(cov, mu=None, maxNumClusters=None):\n",
    "    cov = pd.DataFrame(cov)\n",
    "    if mu is not None:\n",
    "        mu = pd.Series(mu[:, 0])\n",
    "    corr1 = cov2corr(cov)\n",
    "    corr1, clstrs, _ = clusterKMeansBase(corr1, maxNumClusters, n_init=10)\n",
    "    wIntra = pd.DataFrame(0, index=cov.index, columns=clstrs.keys())\n",
    "    for i in clstrs:\n",
    "        cov_ = cov.loc[clstrs[i], clstrs[i]].values\n",
    "        mu_ = (None if mu is None else mu.loc[clstrs[i]].values.reshape(-1, 1))\n",
    "        wIntra.loc[clstrs[i], i] = optPort(cov_, mu_).flatten()\n",
    "    cov_ = wIntra.T.dot(np.dot(cov, wIntra))  # reduce covariance matrix\n",
    "    mu_ = (None if mu is None else wIntra.T.dot(mu))\n",
    "    wInter = pd.Series(optPort(cov_, mu_).flatten(), index=cov_.index)\n",
    "    nco = wIntra.mul(wInter, axis=1).sum(axis=1).values.reshape(-1, 1)\n",
    "    return nco\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monte-carlo simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def corr2cov(corr: np.ndarray, std: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"recovers the covariance matrix from the de-noise correlation matrix\"\"\"\n",
    "    # creating matrix of stds and multiply it by correlations\n",
    "    # elementwise\n",
    "    return corr * np.outer(std, std)\n",
    "\n",
    "\n",
    "def cov2corr(cov: np.ndarray) -> np.ndarray:\n",
    "    # Derive the correlation matrix from a covariance matrix\n",
    "    std = np.sqrt(np.diag(cov))\n",
    "    corr = cov / np.outer(std, std)\n",
    "    corr[corr < -1], corr[corr > 1] = -1, 1  # numerical error\n",
    "    return corr\n",
    "\n",
    "\n",
    "def getPCA(matrix: np.ndarray):\n",
    "    # Get eVal,eVec from a Hermitian matrix\n",
    "    eigen_values, eigen_vectors = np.linalg.eigh(matrix)\n",
    "    indices = eigen_values.argsort()[::-1]  # arguments for sorting eVal desc\n",
    "    eigen_values, eigen_vectors = eigen_values[indices], eigen_vectors[:,\n",
    "                                                                       indices]\n",
    "    # eigen_values = np.diagflat(eigen_values)\n",
    "    return eigen_values, eigen_vectors\n",
    "\n",
    "\n",
    "def denoisedCorr(\n",
    "    sorted_ev: np.ndarray,\n",
    "    eigen_vectors: np.ndarray,\n",
    "    save_top: int\n",
    ") -> np.ndarray:\n",
    "    \"\"\"shrinks the eigenvalues associated with noise, and returns a de-noised\n",
    "    correlation matrix\"\"\"\n",
    "    # Remove noise from corr by fixing random eigenvalues\n",
    "    \n",
    "    # sorted by decreasing order\n",
    "    sorted_ev = sorted_ev.copy()\n",
    "    assert len(sorted_ev.shape) == 1\n",
    "\n",
    "    # replacing each eigen value, less than the maximum expected with \n",
    "    # average eigen value\n",
    "    pad = sorted_ev[save_top:].sum() / (len(sorted_ev) - save_top)\n",
    "    sorted_ev[save_top:] = pad\n",
    "    sorted_ev = np.diag(sorted_ev)\n",
    "    \n",
    "    # svd decomposition\n",
    "    cov1 = np.dot(eigen_vectors, sorted_ev).dot(eigen_vectors.T)\n",
    "    return cov2corr(cov1)\n",
    "\n",
    "\n",
    "def denoise_cov(cov0: np.ndarray, q: float, bandwidth: float):\n",
    "    \"\"\"   \n",
    "    This function computes the correlation matrix associated with a given\n",
    "    covariance matrix, and derives the eigenvalues and eigenvectors\n",
    "    for that correlation matrix. Function denoisedCorr shrinks the eigenvalues\n",
    "    associated with noise, and returns a de-noised correlation matrix. Function\n",
    "    corr2cov recovers the covariance matrix from the de-noise correlation\n",
    "    matrix. In summary, this step shrinks only the eigenvalues associated with\n",
    "    noise, leaving the eigenvalues associated with signal unchanged. \n",
    "    \"\"\"\n",
    "    corr0 = cov2corr(cov0)\n",
    "\n",
    "    # eigen_values - cols a = 0 with a[i] = \\lambda\n",
    "    eigen_values, eigen_vectors = getPCA(corr0)\n",
    "    eigen_max = find_max_eigen_values(eigen_values, q, bandwidth)\n",
    "\n",
    "    # choosing how many top eigen values must be saved, since they are\n",
    "    # higher than the estimated expected maximum eigen value\n",
    "    save_top: int = len(eigen_values) - \\\n",
    "        eigen_values[::-1].searchsorted(eigen_max)\n",
    "\n",
    "    corr1 = denoisedCorr(eigen_values, eigen_vectors, save_top)\n",
    "    cov1 = corr2cov(corr1, np.diag(cov0)**.5)\n",
    "    return cov1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_mu_cov(\n",
    "    mu_true: np.ndarray,\n",
    "    cov_true: np.ndarray,\n",
    "    obs_num: int,\n",
    "    shrink: bool = False\n",
    ") -> T[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Drawing an empirical vector of means and an empirical covariance\n",
    "    matrix\n",
    "\n",
    "    Args:\n",
    "        mu_true (np.ndarray): array of math expectations of returns\n",
    "        cov_true (np.ndarray): covariance matrix of returns\n",
    "        obs_num (int): number of observations to generate\n",
    "        shrink (bool, optional): whether to apply LedoitWolf procedure\n",
    "            to estimate cov matrix\n",
    "\n",
    "    Returns:\n",
    "        T[np.ndarray, np.ndarray]: estimations of sampled observations\n",
    "            expectations and covariance matrix\n",
    "    \"\"\"\n",
    "\n",
    "    x = np.random.multivariate_normal(\n",
    "        mu_true.flatten(),\n",
    "        cov_true,\n",
    "        size=obs_num\n",
    "    )\n",
    "\n",
    "    mu1 = x.mean(axis=0).reshape(-1, 1)\n",
    "    cov1 = cov1 = LedoitWolf().fit(x).covariance_ if shrink else np.cov(x, rowvar=0)\n",
    "    return mu1, cov1\n",
    "\n",
    "\n",
    "def simulate_mc(\n",
    "    mu_true: np.ndarray,\n",
    "    cov_true: np.ndarray,\n",
    "    obs_num: int,\n",
    "    simulations_num: int,\n",
    "    bandwidth: float,\n",
    "    min_var_portf: bool,\n",
    "    shrink: bool = False\n",
    "):\n",
    "    \"\"\" \n",
    "    generating weights for portfolio, based on stock \n",
    "    returns covariance and expected returns for underlying process.\n",
    "\n",
    "    At each monte carlo loop we:\n",
    "        1. Sample `obs_num` from multivariate normal, given true mu and omega\n",
    "           and obtain estimates of mu and omega. \n",
    "        2. Optimize portfolio based on estimates  \n",
    "\n",
    "    Returns \n",
    "    \"\"\"\n",
    "    # sampling portflio weights for each stock\n",
    "    # across different samples\n",
    "\n",
    "    w1 = pd.DataFrame(\n",
    "        columns=range(len(cov_true)),\n",
    "        index=range(simulations_num),\n",
    "        dtype=float\n",
    "    )\n",
    "\n",
    "    w1_d = w1.copy(deep=True)\n",
    "\n",
    "    for i in tqdm(range(simulations_num)):\n",
    "        mu_estimated, cov_estimated = sample_mu_cov(\n",
    "            mu_true,\n",
    "            cov_true,\n",
    "            obs_num,\n",
    "            shrink\n",
    "        )\n",
    "\n",
    "        if min_var_portf:\n",
    "            mu_estimated = None\n",
    "\n",
    "        if bandwidth is not None:\n",
    "            cov_denoised = denoise_cov(\n",
    "                cov_estimated,\n",
    "                obs_num / len(cov_estimated),\n",
    "                bandwidth\n",
    "            )\n",
    "\n",
    "        w1.loc[i] = optPort(cov_denoised, mu_estimated).flatten()\n",
    "        # w1_d.loc[i] = optPort_nco(\n",
    "        #     cov_denoised,\n",
    "        #     mu_estimated,\n",
    "        #     int(len(cov_denoised) / 2)\n",
    "        # ).flatten()\n",
    "\n",
    "    return w1, w1_d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nBlocks, bSize, bCorr = 10, 5, .5\n",
    "np.random.seed(0)\n",
    "# mu0, cov0 = formTrueMatrix(nBlocks, bSize, bCorr)\n",
    "mu0, cov0 = init_mu_cov(nBlocks, bSize, bCorr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "286a71fe92664ad3969c580c54fa6112",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n",
      "OPTIMIZED:  0.99999 2.914184420237471\n"
     ]
    }
   ],
   "source": [
    "simulations_num = 100\n",
    "obs_num = 100\n",
    "shrink = False\n",
    "bandwidth = 0.25\n",
    "\n",
    "\n",
    "results = []\n",
    "\n",
    "for i in tqdm(range(simulations_num)):\n",
    "    mu_estimated, cov_estimated = sample_mu_cov(\n",
    "        mu0,\n",
    "        cov0,\n",
    "        obs_num,\n",
    "        shrink\n",
    "    )\n",
    "    \n",
    "    corr0 = cov2corr(cov_estimated)\n",
    "    q = obs_num / len(cov_estimated)\n",
    "    # eigen_values - cols a = 0 with a[i] = \\lambda\n",
    "    eigen_values, eigen_vectors = getPCA(corr0)\n",
    "    \n",
    "    results.append(eigen_values)\n",
    "    eigen_max = find_max_eigen_values(eigen_values, q, bandwidth)\n",
    "\n",
    "    # choosing how many top eigen values must be saved, since they are\n",
    "    # higher than the estimated expected maximum eigen value\n",
    "    save_top: int = len(eigen_values) - \\\n",
    "        eigen_values[::-1].searchsorted(eigen_max)\n",
    "\n",
    "    corr1 = denoisedCorr(eigen_values, eigen_vectors, save_top)\n",
    "    cov1 = corr2cov(corr1, np.diag(cov0)**.5)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = np.array(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAGdCAYAAACyzRGfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAbnUlEQVR4nO3de4xU5f348c/K4gBmd1tU9hJXpAavWGvEgKgVqqJUSZTWS60EGtvYiFhKjUX9Q2xS1jbB2saWRmNRoqhtvdQGFbdRoBaxSKG11ioWqLSyIVJlga8dq57fH98v8+uwy2WW2Wd3ltcrOYlz5pmZ5+F42Ldnxp2qLMuyAABI5KCengAAcGARHwBAUuIDAEhKfAAASYkPACAp8QEAJCU+AICkxAcAkFR1T09gVx9//HG8/fbbUVNTE1VVVT09HQBgH2RZFtu2bYumpqY46KA9X9vodfHx9ttvR3Nzc09PAwDogo0bN8YRRxyxxzG9Lj5qamoi4n8nX1tb28OzAQD2RXt7ezQ3Nxd+ju9Jr4uPnW+11NbWig8AqDD78pEJHzgFAJISHwBAUuIDAEhKfAAASYkPACAp8QEAJCU+AICkxAcAkJT4AACSEh8AQFLiAwBISnwAAEmJDwAgKfEBACRV3dMTALruqFmLenoKJdtw+4U9PQWgh7nyAQAkJT4AgKTEBwCQlPgAAJISHwBAUuIDAEhKfAAASYkPACAp8QEAJCU+AICkxAcAkJT4AACSEh8AQFLiAwBISnwAAEmJDwAgKfEBACQlPgCApMQHAJCU+AAAkhIfAEBS4gMASEp8AABJiQ8AICnxAQAkJT4AgKTEBwCQlPgAAJISHwBAUuIDAEhKfAAASYkPACAp8QEAJFVSfLS0tMRpp50WNTU1MWTIkLj44ovj9ddfLxozderUqKqqKtpGjx5d1kkDAJWrpPhYunRpTJs2LVasWBGtra3x4Ycfxvjx42PHjh1F4y644ILYtGlTYXvqqafKOmkAoHJVlzL4mWeeKbo9f/78GDJkSKxatSo++9nPFvbncrloaGgozwwBgD5lvz7zsXXr1oiIGDx4cNH+JUuWxJAhQ+KYY46Jr33ta7F58+bdPkc+n4/29vaiDQDou7ocH1mWxcyZM+PMM8+MESNGFPZPmDAhHnzwwXjuuedi7ty5sXLlyvjc5z4X+Xy+0+dpaWmJurq6wtbc3NzVKQEAFaAqy7KsKw+cNm1aLFq0KF544YU44ogjdjtu06ZNMXTo0Hj44Ydj0qRJHe7P5/NFYdLe3h7Nzc2xdevWqK2t7crU4IBx1KxFPT2Fkm24/cKengLQDdrb26Ourm6ffn6X9JmPnaZPnx5PPvlkLFu2bI/hERHR2NgYQ4cOjbVr13Z6fy6Xi1wu15VpAAAVqKT4yLIspk+fHo8//ngsWbIkhg0bttfHbNmyJTZu3BiNjY1dniQA0HeU9JmPadOmxQMPPBALFy6MmpqaaGtri7a2tnj//fcjImL79u1xww03xIsvvhgbNmyIJUuWxMSJE+Owww6LSy65pFsWAABUlpKufMybNy8iIsaOHVu0f/78+TF16tTo169fvPLKK7FgwYJ47733orGxMcaNGxePPPJI1NTUlG3SAEDlKvltlz0ZOHBgLF68eL8mBAD0bb7bBQBISnwAAEmJDwAgKfEBACQlPgCApMQHAJCU+AAAkhIfAEBS4gMASEp8AABJiQ8AICnxAQAkJT4AgKTEBwCQlPgAAJISHwBAUuIDAEhKfAAASVX39ASgtzhq1qKengLAAcGVDwAgKfEBACQlPgCApMQHAJCU+AAAkhIfAEBS4gMASEp8AABJiQ8AICnxAQAkJT4AgKTEBwCQlPgAAJISHwBAUuIDAEhKfAAASYkPACAp8QEAJCU+AICkxAcAkJT4AACSEh8AQFLiAwBISnwAAEmJDwAgKfEBACQlPgCApMQHAJCU+AAAkhIfAEBS4gMASEp8AABJiQ8AIKmS4qOlpSVOO+20qKmpiSFDhsTFF18cr7/+etGYLMti9uzZ0dTUFAMHDoyxY8fGq6++WtZJAwCVq6T4WLp0aUybNi1WrFgRra2t8eGHH8b48eNjx44dhTHf//7344477oi77rorVq5cGQ0NDXHeeefFtm3byj55AKDyVJcy+Jlnnim6PX/+/BgyZEisWrUqPvvZz0aWZXHnnXfGLbfcEpMmTYqIiPvvvz/q6+tj4cKFcc0115Rv5gBARdqvz3xs3bo1IiIGDx4cERHr16+Ptra2GD9+fGFMLpeLs88+O5YvX97pc+Tz+Whvby/aAIC+q8vxkWVZzJw5M84888wYMWJERES0tbVFRER9fX3R2Pr6+sJ9u2ppaYm6urrC1tzc3NUpAQAVoMvxcd1118Wf/vSneOihhzrcV1VVVXQ7y7IO+3a66aabYuvWrYVt48aNXZ0SAFABSvrMx07Tp0+PJ598MpYtWxZHHHFEYX9DQ0NE/O8VkMbGxsL+zZs3d7gaslMul4tcLteVaQAAFaikKx9ZlsV1110Xjz32WDz33HMxbNiwovuHDRsWDQ0N0draWtj3wQcfxNKlS2PMmDHlmTEAUNFKuvIxbdq0WLhwYfzqV7+Kmpqawuc46urqYuDAgVFVVRUzZsyIOXPmxPDhw2P48OExZ86cGDRoUFx55ZXdsgAAoLKUFB/z5s2LiIixY8cW7Z8/f35MnTo1IiJuvPHGeP/99+Paa6+Nd999N0aNGhXPPvts1NTUlGXCAEBlKyk+sizb65iqqqqYPXt2zJ49u6tzAgD6MN/tAgAkJT4AgKTEBwCQlPgAAJISHwBAUuIDAEhKfAAASYkPACAp8QEAJCU+AICkxAcAkJT4AACSEh8AQFLiAwBISnwAAEmJDwAgKfEBACQlPgCApMQHAJCU+AAAkhIfAEBS4gMASEp8AABJiQ8AICnxAQAkJT4AgKTEBwCQlPgAAJISHwBAUuIDAEhKfAAASVX39ATom46atainpwBAL+XKBwCQlPgAAJISHwBAUuIDAEhKfAAASYkPACAp8QEAJCU+AICkxAcAkJT4AACSEh8AQFLiAwBISnwAAEmJDwAgKfEBACQlPgCApMQHAJCU+AAAkhIfAEBS4gMASKrk+Fi2bFlMnDgxmpqaoqqqKp544omi+6dOnRpVVVVF2+jRo8s1XwCgwpUcHzt27IiTTz457rrrrt2OueCCC2LTpk2F7amnntqvSQIAfUd1qQ+YMGFCTJgwYY9jcrlcNDQ0dHlSAEDf1S2f+ViyZEkMGTIkjjnmmPja174Wmzdv3u3YfD4f7e3tRRsA0HeVPT4mTJgQDz74YDz33HMxd+7cWLlyZXzuc5+LfD7f6fiWlpaoq6srbM3NzeWeEgDQi5T8tsveXH755YV/HjFiRIwcOTKGDh0aixYtikmTJnUYf9NNN8XMmTMLt9vb2wUIAPRhZY+PXTU2NsbQoUNj7dq1nd6fy+Uil8t19zQAgF6i23/Px5YtW2Ljxo3R2NjY3S8FAFSAkq98bN++Pd58883C7fXr18eaNWti8ODBMXjw4Jg9e3Z84QtfiMbGxtiwYUPcfPPNcdhhh8Ull1xS1okDAJWp5Ph4+eWXY9y4cYXbOz+vMWXKlJg3b1688sorsWDBgnjvvfeisbExxo0bF4888kjU1NSUb9YAQMUqOT7Gjh0bWZbt9v7Fixfv14QAgL7Nd7sAAEmJDwAgKfEBACQlPgCApMQHAJCU+AAAkhIfAEBS4gMASEp8AABJiQ8AICnxAQAkJT4AgKTEBwCQlPgAAJISHwBAUuIDAEhKfAAASYkPACAp8QEAJCU+AICkxAcAkJT4AACSEh8AQFLiAwBISnwAAEmJDwAgKfEBACQlPgCApMQHAJCU+AAAkhIfAEBS4gMASEp8AABJiQ8AICnxAQAkJT4AgKTEBwCQlPgAAJISHwBAUuIDAEhKfAAASYkPACAp8QEAJFXd0xMADixHzVrU01Pokg23X9jTU4A+w5UPACAp8QEAJCU+AICkxAcAkJT4AACSEh8AQFLiAwBIquT4WLZsWUycODGampqiqqoqnnjiiaL7syyL2bNnR1NTUwwcODDGjh0br776arnmCwBUuJLjY8eOHXHyySfHXXfd1en93//+9+OOO+6Iu+66K1auXBkNDQ1x3nnnxbZt2/Z7sgBA5Sv5N5xOmDAhJkyY0Ol9WZbFnXfeGbfccktMmjQpIiLuv//+qK+vj4ULF8Y111yzf7MFACpeWT/zsX79+mhra4vx48cX9uVyuTj77LNj+fLl5XwpAKBClfW7Xdra2iIior6+vmh/fX19/P3vf+/0Mfl8PvL5fOF2e3t7OacEAPQy3fLFclVVVUW3syzrsG+nlpaWuO2227pjGgBlU4lfiOfL8Oityvq2S0NDQ0T8/ysgO23evLnD1ZCdbrrppti6dWth27hxYzmnBAD0MmWNj2HDhkVDQ0O0trYW9n3wwQexdOnSGDNmTKePyeVyUVtbW7QBAH1XyW+7bN++Pd58883C7fXr18eaNWti8ODBceSRR8aMGTNizpw5MXz48Bg+fHjMmTMnBg0aFFdeeWVZJw4AVKaS4+Pll1+OcePGFW7PnDkzIiKmTJkS9913X9x4443x/vvvx7XXXhvvvvtujBo1Kp599tmoqakp36wBgIpVlWVZ1tOT+G/t7e1RV1cXW7du9RZMBavED+dBX+MDp6RUys9v3+0CACQlPgCApMQHAJCU+AAAkhIfAEBS4gMASEp8AABJiQ8AICnxAQAkJT4AgKTEBwCQlPgAAJISHwBAUuIDAEhKfAAASYkPACAp8QEAJCU+AICkxAcAkJT4AACSEh8AQFLiAwBISnwAAEmJDwAgKfEBACQlPgCApMQHAJCU+AAAkhIfAEBS4gMASEp8AABJVff0BNi7o2Yt6ukpAEDZuPIBACQlPgCApMQHAJCU+AAAkhIfAEBS4gMASEp8AABJiQ8AICnxAQAkJT4AgKTEBwCQlPgAAJISHwBAUuIDAEhKfAAASYkPACAp8QEAJCU+AICkxAcAkJT4AACSKnt8zJ49O6qqqoq2hoaGcr8MAFChqrvjSU888cT4zW9+U7jdr1+/7ngZAKACdUt8VFdXu9oBAHSqWz7zsXbt2mhqaophw4bFFVdcEevWrdvt2Hw+H+3t7UUbANB3lT0+Ro0aFQsWLIjFixfHPffcE21tbTFmzJjYsmVLp+NbWlqirq6usDU3N5d7SgBAL1KVZVnWnS+wY8eOOProo+PGG2+MmTNndrg/n89HPp8v3G5vb4/m5ubYunVr1NbWdufUKsZRsxb19BSACrTh9gt7egocQNrb26Ourm6ffn53y2c+/tshhxwSJ510Uqxdu7bT+3O5XORyue6eBgDQS3T77/nI5/Px2muvRWNjY3e/FABQAcoeHzfccEMsXbo01q9fHy+99FJ88YtfjPb29pgyZUq5XwoAqEBlf9vlH//4R3zpS1+Kd955Jw4//PAYPXp0rFixIoYOHVrulwIAKlDZ4+Phhx8u91MCAH2I73YBAJISHwBAUuIDAEhKfAAASYkPACAp8QEAJCU+AICkxAcAkJT4AACSEh8AQFLiAwBISnwAAEmJDwAgKfEBACQlPgCApMQHAJCU+AAAkhIfAEBS4gMASEp8AABJiQ8AICnxAQAkJT4AgKTEBwCQlPgAAJISHwBAUuIDAEhKfAAASYkPACAp8QEAJCU+AICkqnt6AgB0j6NmLerpKZRsw+0X9vQUSMCVDwAgKfEBACQlPgCApMQHAJCU+AAAkhIfAEBS4gMASEp8AABJiQ8AICnxAQAkJT4AgKTEBwCQ1AH3xXKV+EVLAPRelfhzpae/wM+VDwAgKfEBACQlPgCApMQHAJCU+AAAkhIfAEBS4gMASKrb4uMnP/lJDBs2LAYMGBCnnnpq/Pa3v+2ulwIAKki3xMcjjzwSM2bMiFtuuSVWr14dZ511VkyYMCHeeuut7ng5AKCCdEt83HHHHXH11VfHV7/61Tj++OPjzjvvjObm5pg3b153vBwAUEHK/uvVP/jgg1i1alXMmjWraP/48eNj+fLlHcbn8/nI5/OF21u3bo2IiPb29nJPLSIiPs7/T7c8LwD7r7v+7u9OlfhzpTv+nHc+Z5Zlex1b9vh455134qOPPor6+vqi/fX19dHW1tZhfEtLS9x2220d9jc3N5d7agD0cnV39vQMDgzd+ee8bdu2qKur2+OYbvtiuaqqqqLbWZZ12BcRcdNNN8XMmTMLtz/++OP417/+FYceemin43ub9vb2aG5ujo0bN0ZtbW1PTycZ67buA4F1W/eBoFzrzrIstm3bFk1NTXsdW/b4OOyww6Jfv34drnJs3ry5w9WQiIhcLhe5XK5o3yc+8YlyT6vb1dbWHlD/su5k3QcW6z6wWPeBpRzr3tsVj53K/oHTgw8+OE499dRobW0t2t/a2hpjxowp98sBABWmW952mTlzZkyePDlGjhwZp59+etx9993x1ltvxde//vXueDkAoIJ0S3xcfvnlsWXLlvjOd74TmzZtihEjRsRTTz0VQ4cO7Y6X61G5XC5uvfXWDm8d9XXWbd0HAuu27gNBT6y7KtuX/ycGAKBMfLcLAJCU+AAAkhIfAEBS4gMASEp87EZLS0tUVVXFjBkzdjvmsccei/POOy8OP/zwqK2tjdNPPz0WL15cNOa+++6LqqqqDtu///3vbl5B1+zLupcsWdLpmv76178WjXv00UfjhBNOiFwuFyeccEI8/vjj3Tz7rtuXdU+dOrXTdZ944omFMZVwvGfPnt1hfg0NDXt8zNKlS+PUU0+NAQMGxKc+9an46U9/2mFMbz7epa65r5zbpa67r5zbpa67r5zbERH//Oc/46qrropDDz00Bg0aFJ/5zGdi1apVe3xMT5zf4qMTK1eujLvvvjs+/elP73HcsmXL4rzzzounnnoqVq1aFePGjYuJEyfG6tWri8bV1tbGpk2birYBAwZ05xK6ZF/XvdPrr79etKbhw4cX7nvxxRfj8ssvj8mTJ8cf//jHmDx5clx22WXx0ksvddf0u2xf1/3DH/6waL0bN26MwYMHx6WXXlo0rhKO94knnlg0v1deeWW3Y9evXx+f//zn46yzzorVq1fHzTffHNdff308+uijhTGVcLxLWXNfOrdLWfdOfeHcLmXdfeXcfvfdd+OMM86I/v37x9NPPx1/+ctfYu7cuXv8reE9dn5nFNm2bVs2fPjwrLW1NTv77LOzb3zjGyU9/oQTTshuu+22wu358+dndXV15Z1kNyhl3c8//3wWEdm777672zGXXXZZdsEFFxTtO//887MrrriiTDMuj/053o8//nhWVVWVbdiwobCvEo73rbfemp188sn7PP7GG2/MjjvuuKJ911xzTTZ69OjC7d5+vEtdc2cq8dwudd195dze3+Ndqef2t7/97ezMM88s6TE9dX678rGLadOmxYUXXhjnnntuyY/9+OOPY9u2bTF48OCi/du3b4+hQ4fGEUccERdddFGH/3rqDbqy7lNOOSUaGxvjnHPOieeff77ovhdffDHGjx9ftO/888+P5cuXl2W+5bI/x/vee++Nc889t8Mvz6uE47127dpoamqKYcOGxRVXXBHr1q3b7djdHcuXX345/vOf/+xxTG863qWseVeVfG53Zd194dzen+Ndqef2k08+GSNHjoxLL700hgwZEqecckrcc889e3xMT53f4uO/PPzww/GHP/whWlpauvT4uXPnxo4dO+Kyyy4r7DvuuOPivvvuiyeffDIeeuihGDBgQJxxxhmxdu3ack17v5W67sbGxrj77rvj0UcfjcceeyyOPfbYOOecc2LZsmWFMW1tbR2+SLC+vr7DFw72pP053ps2bYqnn346vvrVrxbtr4TjPWrUqFiwYEEsXrw47rnnnmhra4sxY8bEli1bOh2/u2P54YcfxjvvvLPHMb3leJe65l1V6rld6rr7yrm9P8e7ks/tdevWxbx582L48OGxePHi+PrXvx7XX399LFiwYLeP6bHzu8vXTPqYt956KxsyZEi2Zs2awr5SLsMvXLgwGzRoUNba2rrHcR999FF28sknZ9OnT9+f6ZbN/q57p4suuiibOHFi4Xb//v2zhQsXFo154IEHslwut1/zLZf9XfecOXOyQw89NMvn83sc19uOd2e2b9+e1dfXZ3Pnzu30/uHDh2dz5swp2vfCCy9kEZFt2rQpy7Lef7x3tbc1/7dKPbc7U8q6d6q0c7szpay7ks/t/v37Z6effnrRvunTpxe9hbKrnjq/Xfn4P6tWrYrNmzfHqaeeGtXV1VFdXR1Lly6NH/3oR1FdXR0fffTRbh/7yCOPxNVXXx0///nP93r5/qCDDorTTjut19Ty/qz7v40ePbpoTQ0NDR2qePPmzR3quafsz7qzLIuf/exnMXny5Dj44IP3+Dq97Xh35pBDDomTTjppt3Pc3bGsrq6OQw89dI9jesvx3tXe1rxTJZ/bndnXdf+3Sju3O7Ov6670c7uxsTFOOOGEon3HH398vPXWW7t9TE+d3+Lj/5xzzjnxyiuvxJo1awrbyJEj48tf/nKsWbMm+vXr1+njHnrooZg6dWosXLgwLrzwwr2+TpZlsWbNmmhsbCz3Erqkq+ve1erVq4vWdPrpp0dra2vRmGeffTbGjBlT1vl31f6se+nSpfHmm2/G1VdfvdfX6W3HuzP5fD5ee+213c5xd8dy5MiR0b9//z2O6S3He1d7W3NE5Z/bndmXde+q0s7tzuzruiv93D7jjDPi9ddfL9r3xhtv7PFLXXvs/O7yNZMDwK6X4WfNmpVNnjy5cHvhwoVZdXV19uMf/zjbtGlTYXvvvfcKY2bPnp0988wz2d/+9rds9erV2Ve+8pWsuro6e+mll1IupSR7W/cPfvCD7PHHH8/eeOON7M9//nM2a9asLCKyRx99tDDmd7/7XdavX7/s9ttvz1577bXs9ttvz6qrq7MVK1akXEpJ9rbuna666qps1KhRnT5HJRzvb33rW9mSJUuydevWZStWrMguuuiirKampvDJ/l3XvW7dumzQoEHZN7/5zewvf/lLdu+992b9+/fPfvnLXxbG9PbjXeqa+8q5Xeq6+8q5Xeq6d6r0c/v3v/99Vl1dnX33u9/N1q5dmz344IPZoEGDsgceeKAwprec3+JjD3b9YTRlypTs7LPPLro/IjpsU6ZMKYyZMWNGduSRR2YHH3xwdvjhh2fjx4/Pli9fnm4RXbC3dX/ve9/Ljj766GzAgAHZJz/5yezMM8/MFi1a1OF5fvGLX2THHnts1r9//+y4444r+gusN9rburMsy957771s4MCB2d13393pc1TC8b788suzxsbGrH///llTU1M2adKk7NVXXy3c39m6lyxZkp1yyinZwQcfnB111FHZvHnzOjxvbz7epa65r5zbpa67r5zbXfl3vC+c21mWZb/+9a+zESNGZLlcLjvuuOM6rKe3nN9VWZZlXb9uAgBQGp/5AACSEh8AQFLiAwBISnwAAEmJDwAgKfEBACQlPgCApMQHAJCU+AAAkhIfAEBS4gMASEp8AABJ/T+RwqeVuwVkQgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(results[:, 0]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.91418442])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = simulate_mc(\n",
    "    mu0,\n",
    "    cov0,\n",
    "    1000,\n",
    "    1000,\n",
    "    0.5,\n",
    "    True,\n",
    "    True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 3\n"
     ]
    }
   ],
   "source": [
    "print(*((2, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimation errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# mu0 = np.random.normal(size=(3, 10))\n",
    "# cov0 = np.cov(mu0)\n",
    "\n",
    "# mu1, cov1 = generate_mu_cov(\n",
    "#     mu0.mean(axis=1), cov0, 1000\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w0 = optPort(cov0, None if minVarPortf else mu0)\n",
    "# w0 = np.repeat(w0.T, w1.shape[0], axis=0)  # true allocation\n",
    "# err = (w1-w0).std(axis=0).mean()\n",
    "# err_d = (w1_d-w0).std(axis=0).mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import block_diag\n",
    "\n",
    "\n",
    "def init_mu_cov(\n",
    "    block_num: int,\n",
    "    block_size: int,\n",
    "    block_corr: float,\n",
    "    std_true: O[np.ndarray] = None\n",
    ") -> T[np.ndarray, pd.DataFrame]:\n",
    "    \"\"\"Code snippet 7 creates a random vector of means and a random covariance\n",
    "    matrix that represent a stylized version of a 50 securities portfolio,\n",
    "    grouped in 10 blocks with intra-cluster correlations of 0.5. This vector\n",
    "    and matrix characterize the “true” process that generates observations,\n",
    "    {𝜇, 𝑉}.  We set a seed for the purpose of reproducing results across runs\n",
    "    with different parameters. In practice, the pair {𝜇, 𝑉} does not need to be\n",
    "    simulated, and MCOS receives {𝜇, 𝑉} as an input.\"\"\"\n",
    "\n",
    "    # create block-diagonal matrix\n",
    "    corr0 = generate_correlation_block_matrix(\n",
    "        block_num,\n",
    "        block_size,\n",
    "        block_corr\n",
    "    )\n",
    "\n",
    "    # shuffling columns and make rows correspond to columns\n",
    "    cols = corr0.columns.tolist()\n",
    "    np.random.shuffle(cols)\n",
    "    corr0 = corr0.loc[cols, cols].copy(deep=True)\n",
    "\n",
    "    if std_true is None:\n",
    "        std_true = np.random.uniform(.05, .2, corr0.shape[0])\n",
    "    else:\n",
    "        std_true = np.array([std_true]*corr0.shape[1])\n",
    "\n",
    "    # transforming correlation matrix to covariance matrix\n",
    "    cov0 = corr2cov(corr0, std_true)\n",
    "    mu0 = np.random.normal(std_true, std_true, cov0.shape[0]).reshape(-1, 1)\n",
    "    return mu0, cov0\n",
    "\n",
    "\n",
    "def generate_correlation_block_matrix(\n",
    "    block_num: int,\n",
    "    block_size: int,\n",
    "    block_corr: float\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Creates correlation block matrix from specified settings\n",
    "\n",
    "    Args:\n",
    "        block_num (int): amount of correlation clusters\n",
    "        block_size (int): amount of stocks in each correlation cluster\n",
    "        block_corr (float): correlation among stocks in cluster\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: matrix of \n",
    "            (block_num * block_size,  block_num * block_size)\n",
    "        size, representing pairwise stock correlations\n",
    "    \"\"\"\n",
    "    # creating 1 block\n",
    "    block = np.ones((block_size, block_size)) * block_corr\n",
    "    np.fill_diagonal(block, 1)\n",
    "    # creating nBlocks from 1 block\n",
    "    corr = block_diag(*([block] * block_num))\n",
    "    return pd.DataFrame(corr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating correlation matrix of 50 stocks, assuming, that they are clustered by\n",
    "correlation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('dev')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "df99d5e3cce6806f7fb5d994b7709b76507bd677cb41783744f9e916a4c54927"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
